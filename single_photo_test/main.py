import torch
import torch.nn as nn
import torch.optim as optim
import torch.fft
import numpy as np
import cv2
import matplotlib.pyplot as plt
import math
from tqdm import tqdm
from skimage.metrics import structural_similarity as ssim_sklearn
import torch
import numpy as np

# ==========================================
# 1. å®šä¹‰ä¸€ä¸ªè®¡ç®— PSNR å’Œ SSIM çš„å·¥å…·å‡½æ•°
# ==========================================
def calc_metrics(pred_tensor, gt_tensor):
    """
    è¾“å…¥: (1, 3, H, W) çš„ Tensor, èŒƒå›´ 0~1
    è¾“å‡º: psnr, ssim (float)
    """
    # --- 1. å‡†å¤‡æ•°æ® (è½¬ numpy + è°ƒæ•´ç»´åº¦) ---
    # Tensor (1,3,H,W) -> Numpy (H,W,3)
    pred_np = pred_tensor.squeeze().permute(1, 2, 0).cpu().numpy()
    gt_np   = gt_tensor.squeeze().permute(1, 2, 0).cpu().numpy()
    
    # ç¡®ä¿èŒƒå›´åœ¨ 0~1 (é˜²æ­¢ float è¯¯å·®å¯¼è‡´ç•¥å¾®è¶Šç•Œ)
    pred_np = np.clip(pred_np, 0, 1)
    gt_np   = np.clip(gt_np, 0, 1)

    # --- 2. è®¡ç®— PSNR ---
    # å…¬å¼: 10 * log10(MAX^2 / MSE)
    mse = np.mean((pred_np - gt_np) ** 2)
    if mse == 0:
        psnr = 100.0 # å®Œç¾åŒ¹é…
    else:
        psnr = 10 * np.log10(1.0 / mse)

    # --- 3. è®¡ç®— SSIM ---
    # channel_axis=2 è¡¨ç¤ºç¬¬3ä¸ªç»´åº¦æ˜¯é€šé“ (H, W, C)
    # data_range=1.0 è¡¨ç¤ºåƒç´ å€¼èŒƒå›´æ˜¯ 0~1
    try:
        ssim = ssim_sklearn(
            gt_np, 
            pred_np, 
            data_range=1.0, 
            channel_axis=2  # æ–°ç‰ˆ skimage å†™æ³•
        )
    except TypeError:
        # å…¼å®¹æ—§ç‰ˆ skimage (å¦‚æœæŠ¥é”™ç”¨è¿™ä¸ª)
        ssim = ssim_sklearn(
            gt_np, 
            pred_np, 
            data_range=1.0, 
            multichannel=True 
        )

    return psnr, ssim
# ==========================================
# 1. ç‰©ç†å±‚: æ”¯æŒå•é€šé“ Z å’Œ Phi çš„ ASM
# ==========================================
def asm_propagate_broadcast(U0, z, phi, wavelengths):
    """
    U0: (B, 3, H, W) - å¤æŒ¯å¹…åˆå§‹åœº
    z:  (B, 1, H, W) - ç‰©ç†è·ç¦» (2DçŸ©é˜µ)
    phi:(B, 1, H, W) - ç›¸ä½è°ƒåˆ¶ (2DçŸ©é˜µ)
    wavelengths: (3,) - RGBæ³¢é•¿
    """
    b, c, h, w = U0.shape
    device = U0.device
    
    # 1. æ„å»ºå¤æŒ¯å¹… (Amplitude * exp(j * phi))
    # æ³¨æ„: phi æ˜¯ (B,1,H,W), ä¼šè‡ªåŠ¨å¹¿æ’­ç»™ 3 ä¸ªé€šé“
    U_input = U0 * torch.exp(1j * phi)

    # 2. é¢‘ç‡ç½‘æ ¼
    fx = torch.fft.fftfreq(w, d=1.0, device=device)
    fy = torch.fft.fftfreq(h, d=1.0, device=device)
    FX, FY = torch.meshgrid(fx, fy, indexing='xy') # æ³¨æ„ meshgrid é¡ºåº
    FX, FY = FX.unsqueeze(0).unsqueeze(0), FY.unsqueeze(0).unsqueeze(0) # (1,1,H,W)

    # 3. å‡†å¤‡æ³¢é•¿ (1, 3, 1, 1)
    lam = wavelengths.to(device).view(1, c, 1, 1)
    
    # 4. è®¡ç®—ä¼ é€’å‡½æ•° H
    # å…¬å¼: H = exp(j * 2pi/lambda * z * sqrt(1 - (lambda*fx)^2 ...))
    # z æ˜¯ (B,1,H,W), lam æ˜¯ (1,3,1,1) -> ç»“æœè‡ªåŠ¨å¹¿æ’­ä¸º (B,3,H,W)
    squared_term = 1 - (lam * FX)**2 - (lam * FY)**2
    squared_term = torch.clamp(squared_term, min=0) # ç‰©ç†æˆªæ–­
    
    k = 2 * math.pi / lam
    phase_delay = k * z * torch.sqrt(squared_term)
    H = torch.exp(1j * phase_delay)

    # 5. é¢‘åŸŸä¼ æ’­
    U_freq = torch.fft.fft2(U_input)
    U_z_freq = U_freq * H
    U_z = torch.fft.ifft2(U_z_freq)
    
    J = torch.abs(U_z)
    return J

# ==========================================
# 2. ç½‘ç»œæ¨¡å‹ (ä¿®æ”¹ä¸ºè¾“å‡º 2D çŸ©é˜µ)
# ==========================================
class _ResBlock(nn.Module):
    def __init__(self, ch):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(ch, ch, 3, 1, 1), nn.GroupNorm(1, ch), nn.SiLU(),
            nn.Conv2d(ch, ch, 3, 1, 1), nn.GroupNorm(1, ch)
        )
        self.act = nn.SiLU()
    def forward(self, x): return self.act(x + self.net(x))

class SingleChPredictor(nn.Module):
    """é€šç”¨çš„å•é€šé“é¢„æµ‹å™¨ (ç”¨äº Z å’Œ Phase)"""
    def __init__(self, in_ch=3, hidden=16):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, hidden, 3, 1, 1),
            _ResBlock(hidden),
            _ResBlock(hidden),
            nn.Conv2d(hidden, 1, 1) # <--- å…³é”®ï¼šè¾“å‡ºé€šé“ä¸º 1
        )
    def forward(self, x): return self.net(x)

class SimpleEndoNet(nn.Module):
    def __init__(self):
        super().__init__()
        # ç‰©ç†æ³¢é•¿ (çº¢/ç»¿/è“)
        self.register_buffer('wavelengths', torch.tensor([0.66, 0.53, 0.45]))
        
        # ä¸¤ä¸ªé¢„æµ‹å™¨ï¼Œéƒ½è¾“å‡º (B, 1, H, W)
        self.phase_net = SingleChPredictor()
        self.z_net = SingleChPredictor()
        
        # MixHead
        self.mix = nn.Sequential(
            nn.Conv2d(3+2, 32, 3, 1, 1), nn.SiLU(),
            nn.Conv2d(32, 3, 1)
        )
        self.luma_w = torch.tensor([0.299, 0.587, 0.114]).view(1,3,1,1)

    def forward(self, x):
        # 1. é¢„æµ‹ç‰©ç†å‚æ•° (2DçŸ©é˜µ)
        phi_raw = self.phase_net(x)
        z_raw = self.z_net(x)
        
        # æ¿€æ´»å‡½æ•°æ§åˆ¶èŒƒå›´
        phi = math.pi * torch.tanh(phi_raw)       # -pi åˆ° pi
        z = 0.1 * torch.sigmoid(z_raw)            # 0 åˆ° 0.1 (å•ä½ä»»æ„ï¼Œå‡è®¾æ˜¯å¾®è·)
        
        # 2. ASM ä¼ æ’­
        # æŠŠ x å½“ä½œæŒ¯å¹… A (å½’ä¸€åŒ–), ç›¸ä½ç”± phi æä¾›
        J = asm_propagate_broadcast(x, z, phi, self.wavelengths)
        
        # 3. Mix & Residual
        # ç®€å•çš„ç»“æ„æå–
        x_luma = (x * self.luma_w.to(x.device)).sum(1, keepdim=True)
        J_luma = (J * self.luma_w.to(x.device)).sum(1, keepdim=True)
        diff = J_luma - x_luma
        
        inp = torch.cat([x, J_luma, diff], dim=1)
        delta = self.mix(inp)
        
        return x + delta, z, phi

def cv_imread(file_path):
    """
    ä¸“é—¨ç”¨æ¥è¯»å–å¸¦ä¸­æ–‡è·¯å¾„å›¾ç‰‡çš„å‡½æ•°
    """
    # 1. å…ˆç”¨ numpy æŠŠæ–‡ä»¶è¯»æˆäºŒè¿›åˆ¶æµ
    cv_img = cv2.imdecode(np.fromfile(file_path, dtype=np.uint8), -1)
    
    # 2. å¦‚æœè¯»å‡ºæ¥æ˜¯ None (æ¯”å¦‚è·¯å¾„ä¸å¯¹)ï¼Œç›´æ¥æŠ›é”™
    if cv_img is None:
        raise ValueError(f"âŒ è¯»å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {file_path}")
        
    return cv_img
# è¿™ç§ç»„åˆé€šå¸¸æ•ˆæœæœ€å¥½ï¼šæ—¢ä¿çœŸåº¦é«˜ï¼ˆMSEï¼‰ï¼Œåˆç»†èŠ‚æ¸…æ™°ï¼ˆL1ï¼‰
class HybridLoss(nn.Module):
    def __init__(self):
        super().__init__()
        self.l1 = nn.L1Loss()
        self.mse = nn.MSELoss()
        
    def forward(self, pred, target):
        # 0.8 å€çš„ L1 (ä¸ºäº†è¾¹ç¼˜é”åˆ©) + 0.2 å€çš„ MSE (ä¸ºäº† PSNR è·‘åˆ†é«˜)
        return 0.2 * self.l1(pred, target) + 0.8 * self.mse(pred, target)
        
loss_fn = HybridLoss()
# ==========================================
# 3. å®éªŒè®¾ç½® (å•å›¾è®­ç»ƒ - çœŸå®æˆå¯¹æ•°æ®ç‰ˆ)
# ==========================================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ Device: {device}")

# --- A. å‡†å¤‡æ•°æ® (è¯»å–åŒå›¾) ---

# ğŸ‘‡ 1. åœ¨è¿™é‡Œå¡«å…¥ä¸¤å¼ å›¾ç‰‡çš„è·¯å¾„
clean_path = r"D:\Desktop\æ¯•ä¸šè®ºæ–‡\code\data\RESIDE-IN\train\GT\1_1_0.90179.png"   # æ¸…æ™°çš„ Ground Truth å›¾ç‰‡
hazy_path  = r"D:\Desktop\æ¯•ä¸šè®ºæ–‡\code\data\RESIDE-IN\train\hazy\1_1_0.90179.png"    # å¯¹åº”çš„ é›¾å›¾ Input

# è¯»å–å›¾ç‰‡
img_clean_bgr = cv_imread(clean_path)
img_hazy_bgr  = cv_imread(hazy_path)

# æ£€æŸ¥æ˜¯å¦è¯»å–æˆåŠŸ
if img_clean_bgr is None: raise ValueError(f"âŒ æ‰¾ä¸åˆ°æ¸…æ™°å›¾: {clean_path}")
if img_hazy_bgr is None:  raise ValueError(f"âŒ æ‰¾ä¸åˆ°é›¾å›¾: {hazy_path}")

# ğŸ‘‡ 2. å¼ºåˆ¶ç»Ÿä¸€å°ºå¯¸
# ç¥ç»ç½‘ç»œè®­ç»ƒè¦æ±‚è¾“å…¥å’Œè¾“å‡ºå¿…é¡»åƒç´ å¯¹é½ï¼Œå°ºå¯¸å®Œå…¨ä¸€è‡´
# å»ºè®®ç¼©æ”¾åˆ° 256x256 æˆ– 512x512ï¼Œè¿‡å¤§æ˜¾å­˜ä¼šçˆ†
H, W = 256, 256
img_clean_bgr = cv2.resize(img_clean_bgr, (H, W))
img_hazy_bgr  = cv2.resize(img_hazy_bgr,  (H, W))

# ğŸ‘‡ 3. é¢„å¤„ç† (è½¬ RGB -> å½’ä¸€åŒ– 0~1)
gt_img = cv2.cvtColor(img_clean_bgr, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0
input_img = cv2.cvtColor(img_hazy_bgr, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0

# ğŸ‘‡ 4. è½¬ Tensor (1, 3, H, W)
t_gt = torch.from_numpy(gt_img).permute(2,0,1).unsqueeze(0).to(device)    # Ground Truth
t_in = torch.from_numpy(input_img).permute(2,0,1).unsqueeze(0).to(device) # Input (Hazy)

print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
print(f"   æ¸…æ™°å›¾ GT   : {clean_path} {t_gt.shape}")
print(f"   é›¾å›¾ Input  : {hazy_path} {t_in.shape}")

# --- B. åˆå§‹åŒ– ---
model = SimpleEndoNet().to(device)
model.load_state_dict(torch.load("model.pth"))
optimizer = optim.Adam(model.parameters(), lr=0.01) # å•å›¾è®­ç»ƒå­¦ä¹ ç‡å¯ä»¥å¤§ç‚¹
loss_fn = HybridLoss()

# --- C. è®­ç»ƒå¾ªç¯ ---
epochs = 4000
pbar = tqdm(range(epochs))

loss_history = []
psnr_history = []
ssim_history = []
for i in pbar:
    optimizer.zero_grad()
    
    # å‰å‘
    out, z_map, phi_map = model(t_in)
    
    # è®¡ç®— Loss (è®©è¾“å‡ºé€¼è¿‘ GT)
    loss = loss_fn(out, t_gt)
    
    # åå‘
    loss.backward()
    optimizer.step()
    
    loss_history.append(loss.item())
    # pbar.set_description(f"Loss: {loss.item():.6f}")
    
    if i % 100 == 0:
        # ç®€å•çš„å­¦ä¹ ç‡è¡°å‡
        for param_group in optimizer.param_groups:
            param_group['lr'] *= 0.9
    # --- B. æ¯ 50 è½®è¯„ä¼°ä¸€æ¬¡ ---
    if (i + 1) % 50 == 0:
        model.eval() # ğŸ”• å…³é—­æ¢¯åº¦è®¡ç®—å’Œ Dropout
        with torch.no_grad():
            # é¢„æµ‹ä¸€æ¬¡
            val_out, _, _ = model(t_in)
            
            # è®¡ç®—æŒ‡æ ‡
            cur_psnr, cur_ssim = calc_metrics(val_out, t_gt)
            
            # è®°å½•
            psnr_history.append(cur_psnr)
            ssim_history.append(cur_ssim)
            
            # åœ¨è¿›åº¦æ¡ä¸Šæ˜¾ç¤º (çœ‹èµ·æ¥å¾ˆä¸“ä¸š)
            pbar.set_description(
                f"Loss:{loss.item():.4f} | PSNR:{cur_psnr:.2f}dB | SSIM:{cur_ssim:.4f}"
            )
            
            # å¯é€‰ï¼šå¦‚æœä½ æƒ³çœ‹åˆ°å…·ä½“çš„æ‰“å°
            # print(f"\n[Epoch {i+1}] PSNR: {cur_psnr:.2f} | SSIM: {cur_ssim:.4f}")

# ==========================================
# 4. ç»“æœå¯è§†åŒ–
# ==========================================
model.eval()
with torch.no_grad():
    out, z_map, phi_map = model(t_in)

torch.save(model.state_dict(), "model.pth")

# è½¬å› numpy
res_img = out.squeeze().permute(1,2,0).cpu().numpy().clip(0,1)
in_show = input_img # HWC
gt_show = gt_img    # HWC
z_show = z_map.squeeze().cpu().numpy()
phi_show = phi_map.squeeze().cpu().numpy()

plt.figure(figsize=(15, 8))

# 1. è¾“å…¥ (æ¨¡æ‹Ÿé›¾å›¾)
plt.subplot(2, 4, 1)
plt.title("Input (Hazy)")
plt.imshow(in_show)
plt.axis('off')

# 2. ä½ çš„ç½‘ç»œè¾“å‡º
plt.subplot(2, 4, 2)
plt.title(f"Output (Dehazed)\nLoss: {loss_history[-1]:.5f}")
plt.imshow(res_img)
plt.axis('off')

# 3. Ground Truth
plt.subplot(2, 4, 3)
plt.title("Ground Truth")
plt.imshow(gt_show)
plt.axis('off')

# 4. é¢„æµ‹çš„ Z çŸ©é˜µ (ç‰©ç†è·ç¦»)
plt.subplot(2, 4, 4)
plt.title("Predicted Distance Z (2D Matrix)")
plt.imshow(z_show, cmap='inferno')
plt.colorbar()
plt.axis('off')

# 5. é¢„æµ‹çš„ Phase çŸ©é˜µ (ç›¸ä½)
plt.subplot(2, 4, 5)
plt.title("Predicted Phase Phi (2D Matrix)")
plt.imshow(phi_show, cmap='twilight')
plt.colorbar()
plt.axis('off')

# 6. Loss æ›²çº¿
plt.subplot(2, 4, 6)
plt.title("Training Loss")
plt.plot(loss_history)
plt.grid(True)

plt.subplot(2, 4, 7)
plt.title("PSNR")
plt.plot(psnr_history)
plt.grid(True)

plt.subplot(2, 4, 8)
plt.title("SSIM")
plt.plot(ssim_history)
plt.grid(True)

plt.tight_layout()
plt.show()