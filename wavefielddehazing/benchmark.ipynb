{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e168e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from model import EndoWaveNet  # å‡è®¾ä½ æŠŠä¸Šä¸€æ®µä»£ç ä¿å­˜ä¸ºäº† model.py\n",
    "\n",
    "def measure_inference_speed(model, height=256, width=256, batch_size=1, device='cuda', iterations=300):\n",
    "    \"\"\"\n",
    "    æ ‡å‡†çš„ FPS æµ‹é€Ÿå‡½æ•°\n",
    "    \"\"\"\n",
    "    # 1. å‡†å¤‡æ•°æ®\n",
    "    dummy_input = torch.randn(batch_size, 3, height, width).to(device)\n",
    "    \n",
    "    # 2. åˆå§‹åŒ– CUDA äº‹ä»¶ (ç”¨äºç²¾å‡†è®¡æ—¶)\n",
    "    starter = torch.cuda.Event(enable_timing=True)\n",
    "    ender = torch.cuda.Event(enable_timing=True)\n",
    "    \n",
    "    # 3. é¢„çƒ­ (Warm-up)\n",
    "    # GPU åœ¨åˆšå¼€å§‹è¿è¡Œæ—¶éœ€è¦åˆå§‹åŒ–ç¼“å­˜ï¼Œå‰å‡ æ¬¡è¿è¡Œé€šå¸¸å¾ˆæ…¢ä¸”ä¸ç¨³å®š\n",
    "    # æˆ‘ä»¬å…ˆç©ºè·‘ 50 æ¬¡ï¼Œè®© GPU è¿›å…¥çŠ¶æ€\n",
    "    print(f\"ğŸ”¥ æ­£åœ¨é¢„çƒ­ GPU (Warm-up)...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(50):\n",
    "            _ = model(dummy_input)\n",
    "    \n",
    "    # 4. æ­£å¼æµ‹é€Ÿ\n",
    "    print(f\"â±ï¸ å¼€å§‹æµ‹é€Ÿ (è¿è¡Œ {iterations} æ¬¡, Batch={batch_size}, Size={height}x{width})...\")\n",
    "    timings = np.zeros((iterations, 1))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for rep in range(iterations):\n",
    "            starter.record()\n",
    "            \n",
    "            # === è¿è¡Œæ¨¡å‹ ===\n",
    "            _ = model(dummy_input)\n",
    "            # =============\n",
    "            \n",
    "            ender.record()\n",
    "            \n",
    "            # ç­‰å¾… GPU å®Œæˆå½“å‰è¿™è½®è®¡ç®—\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            # è®°å½•æ—¶é—´ (æ¯«ç§’)\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "\n",
    "    # 5. è®¡ç®—ç»“æœ\n",
    "    mean_syn = np.sum(timings) / iterations\n",
    "    std_syn = np.std(timings)\n",
    "    fps = (1000.0 / mean_syn) * batch_size # 1000ms / å¹³å‡è€—æ—¶ * Batchæ•°\n",
    "    \n",
    "    return mean_syn, std_syn, fps\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ================= é…ç½®åŒºåŸŸ =================\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    H, W = 256, 256  # è¾“å…¥åˆ†è¾¨ç‡\n",
    "    # ===========================================\n",
    "\n",
    "    print(f\"=======================================\")\n",
    "    print(f\"ğŸš€ EndoWaveNet æé€ŸåŸºå‡†æµ‹è¯•\")\n",
    "    print(f\"   Device: {DEVICE} ({torch.cuda.get_device_name(0) if DEVICE=='cuda' else 'CPU'})\")\n",
    "    print(f\"=======================================\")\n",
    "\n",
    "    # 1. åŠ è½½æ¨¡å‹\n",
    "    model = EndoWaveNet().to(DEVICE)\n",
    "    model.eval() # å¿…é¡»å¼€å¯ eval æ¨¡å¼ (å…³é—­ Dropout/BatchNorm æ›´æ–°)\n",
    "\n",
    "    # æ‰“å°å‚æ•°é‡\n",
    "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"ğŸ“¦ æ¨¡å‹å‚æ•°é‡: {params/1000:.2f} K\")\n",
    "\n",
    "    # 2. æµ‹è¯•ä¸åŒ Batch Size çš„è¡¨ç°\n",
    "    # é€šå¸¸ Batch è¶Šå¤§ï¼Œååé‡(FPS)è¶Šé«˜ï¼Œä½†å»¶è¿Ÿä¹Ÿè¶Šé«˜\n",
    "    batch_sizes = [1, 4, 8, 16]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æµ‹é€Ÿç»“æœ:\")\n",
    "    print(f\"{'Batch':<8} | {'Resolution':<12} | {'Latency (ms)':<15} | {'FPS':<10}\")\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "    for b in batch_sizes:\n",
    "        try:\n",
    "            mean_time, _, fps = measure_inference_speed(\n",
    "                model, \n",
    "                height=H, \n",
    "                width=W, \n",
    "                batch_size=b, \n",
    "                device=DEVICE\n",
    "            )\n",
    "            print(f\"{b:<8} | {H}x{W:<8} | {mean_time:.2f} ms        | {fps:.2f}\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"{b:<8} | {H}x{W:<8} | OOM (æ˜¾å­˜ä¸è¶³)    | -\")\n",
    "            break\n",
    "\n",
    "    print(\"-\" * 55)\n",
    "    print(\"âœ… æµ‹è¯•å®Œæˆï¼\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
